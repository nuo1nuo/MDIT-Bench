<div align="center">
  <h1>MDIT-Bench: Evaluating the Dual-Implicit Toxicity in Large Multimodal Models</h1>
  <span><strong><i>We are organizing the data of MDIT-Bench. If you are interested in our work, please star ⭐ our project.</i></strong></span>

  <h4>  ⏬ <a href="" target="_blank">Data</a> • 📃 <a href="" target="_blank">Paper</a>
  </h4>
</div>

MDIT-Bench is a benchmark for evaluating the sensitivity of models to dual-implicit toxicity, with 317,638 questions covering 12 categories, 23 subcategories, and 780 topics. MDIT-Bench includes three difficulty levels, and we propose a metric to measure the toxicity gap exhibited by the model across them. Please check our [paper]() for more details.

## News
**🎉 `2025/05/15`:** MDIT-Bench is accepted by the ACL 2025 Findings.
